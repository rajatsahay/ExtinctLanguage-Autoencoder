# -*- coding: utf-8 -*-
"""KuzushijiMNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13K9xxyOFi6TECXUqF2x0VkD8rR05MC0Z

Pulling Dataset From Kaggle
"""

from google.colab import files
!pip install -q kaggle

uploaded=files.upload()

from googleapiclient.discovery import build
import io, os
from googleapiclient.http import MediaIoBaseDownload
from google.colab import auth
auth.authenticate_user()
drive_service = build('drive', 'v3')
results = drive_service.files().list(
        q="name = 'kaggle.json'", fields="files(id)").execute()
kaggle_api_key = results.get('files', [])
filename = "/root/.kaggle/kaggle.json"  # NOTE: This is different from the Medium post!
os.makedirs(os.path.dirname(filename), exist_ok=True)
request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])
fh = io.FileIO(filename, 'wb')
downloader = MediaIoBaseDownload(fh, request)
done = False
while done is False:
    status, done = downloader.next_chunk()
    print("Download %d%%." % int(status.progress() * 100))
os.chmod(filename, 600)

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets list

!kaggle datasets download -d anokas/kuzushiji

!unzip /content/kuzushiji.zip



"""Main Code"""

from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten, Lambda
from keras.layers.advanced_activations import LeakyReLU
from keras.models import Sequential, Model
from keras.optimizers import Adam
import keras.backend as K

import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image

train_images=np.load('/content/k49-train-imgs.npz')['arr_0']
test_images=np.load('/content/k49-test-imgs.npz')['arr_0']
train_labels=np.load('/content/k49-train-labels.npz')['arr_0']
test_labels=np.load('/content/k49-test-labels.npz')['arr_0']

img_rows=28
img_cols=28
channels=1
img_shape=(img_rows,img_cols,channels)
latent_dim=10
batch_size=16
epsilon_std=1.0

def plot_sample_images_data(images,labels):
  plt.figure(figsize=(12,12))
  for i in range(10):
    imgs=images[np.where(labels==i)]
    lbls=labels[np.where(labels==i)]
    for j in range(10):
      plt.subplot(10,10,i*10+j+1)
      plt.xticks([])
      plt.yticks([])
      plt.grid(False)
      plt.imshow(imgs[j],cmap=plt.cm.binary)
      plt.xlabel(lbls[j])

plot_sample_images_data(train_images,train_labels)

#taken from github.com/
def sampling(args):
  z_mean,z_log_var=args
  epsilon=K.random_normal(shape=(batch_size,latent_dim),mean=0.,stddev=epsilon_std)
  return z_mean+K.exp(z_log_var/2)*epsilon

def build_encoder():
  img=Input(shape=img_shape)
  h=Flatten()(img)
  h=Dense(512)(h)
  h=LeakyReLU(alpha=0.2)(h)
  h=Dense(512)(h)
  h=LeakyReLU(alpha=0.2)(h)
  mu=Dense(latent_dim)(h)
  log_var=Dense(latent_dim)(h)
  z=Lambda(sampling,output_shape=(latent_dim,),name='z')([mu,log_var])
  return Model(img,z)

def build_decoder():
  model=Sequential()
  model.add(Dense(512,input_dim=latent_dim))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(512))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(np.prod(img_shape),activation='tanh'))
  model.add(Reshape(img_shape))
  #model.summary()
  z=Input(shape=(latent_dim,))
  img=model(z)
  return Model(z,img)

def build_discriminator():
  model=Sequential()
  model.add(Dense(1024,input_dim=latent_dim))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(512))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(256))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(1,activation='sigmoid'))
  #model.summary()
  encoded_repr=Input(shape=(latent_dim,))
  validity=model(encoded_repr)
  return Model(encoded_repr,validity)

#build GAN
optimizer=Adam(0.0002, 0.5)

discriminator=build_discriminator()
discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])

encoder=build_encoder()
decoder=build_decoder()

img=Input(shape=img_shape)
encoded_repr=encoder(img)
reconstructed_img=decoder(encoded_repr)

#For the adversarial_autoencoder model we will only train the generator
#if discriminator is attached to generator, set this flag to fix discriminator
discriminator.trainable=False

validity=discriminator(encoded_repr)

adversarial_autoencoder=Model(img, [reconstructed_img, validity])
adversarial_autoencoder.compile(loss=['mse', 'binary_crossentropy'], loss_weights=[0.999, 0.001], optimizer=optimizer)

#trainGAN
def train(epochs,batch_size=128,sample_interval=50):
  X_train=train_images

  #normalization (rescale -1 to 1)
  X_train=(X_train.astype(np.float32)-127.5)/127.5
  X_train=np.expand_dims(X_train,axis=3)

  #adversarial ground truths
  valid=np.ones((batch_size,1))
  fake=np.zeros((batch_size,1))

  for epoch in range(epochs):
    idx=np.random.randint(0,X_train.shape[0],batch_size)
    imgs=X_train[idx]

    latent_fake=encoder.predict(imgs)
    latent_real=np.random.normal(size=(batch_size,latent_dim))

    #let latent's real output be close to 1
    d_loss_real=discriminator.train_on_batch(latent_real, valid)
    #let latent's fake output be close to 0
    d_loss_fake=discriminator.train_on_batch(latent_fake,fake)
    d_loss=0.7*np.add(d_loss_real,d_loss_fake)

    #train generator
    #decrease reconstruction error
    g_loss=adversarial_autoencoder.train_on_batch(imgs,[imgs,valid])

    if epoch%sample_interval==0:
      print("%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]" % (epoch, d_loss[0], 100 * d_loss[1], g_loss[0], g_loss[1]))
      sample_images(epoch)

def sample_images(epoch):
  r,c=5,5
  z=np.random.normal(size=(r*c,latent_dim))
  gen_imgs=decoder.predict(z)
  gen_imgs=0.5*gen_imgs+0.5
  fig,axs=plt.subplots(r,c)
  cnt=0
  for i in range(r):
    for j in range(c):
      axs[i,j].imshow(gen_imgs[cnt,:,:,0],cmap=plt.cm.binary)
      axs[i,j].axis('off')
      cnt+=1
  fig.savefig("kmnist_%d.png" % epoch)
  plt.close()

epochs=90000
sample_interval=2000
sample_count=epochs/sample_interval

train(epochs=epochs,batch_size=batch_size,sample_interval=sample_interval)

Image.open('mnist_88000.png')

"""Ref: 
<a href=https://github.com/eriklindernoren/Keras-GAN#adversarial-autoencoder> Keras Autoencoder </a>
"""